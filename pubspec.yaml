name: tokenizer
description: Converts a stream of strings into a stream of tokens
version: 1.0.0
repository: https://github.com/lesnitsky/tokenizer

environment:
  sdk: ">=2.19.0 <3.0.0"

dev_dependencies:
  lints: ^2.0.0
  test: ^1.21.0
